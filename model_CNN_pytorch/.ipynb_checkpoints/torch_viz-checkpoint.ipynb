{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempted relative import in non-package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ea705c1f88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../utils\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tmain/Perforce/xplat/branches/research_dev/researchjunction/eyegaze/stereo/eyetracker/stereoeyetracker/model_CNN_pytorch/training_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mqueue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mqueue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempted relative import in non-package"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "from models import SubCNN\n",
    "import training_utils as tu\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "import logging_utils as lu\n",
    "\n",
    "from time import time\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "from graphviz import Digraph\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "def make_dot(var):\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if isinstance(var, Variable):\n",
    "                value = '('+(', ').join(['%d'% v for v in var.size()])+')'\n",
    "                dot.node(str(id(var)), str(value), fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'previous_functions'):\n",
    "                for u in var.previous_functions:\n",
    "                    dot.edge(str(id(u[0])), str(id(var)))\n",
    "                    add_nodes(u[0])\n",
    "    add_nodes(var.creator)\n",
    "    return dot\n",
    "\n",
    "\n",
    "def train(settings):\n",
    "    \"\"\"Train NN for eye tracking regression\n",
    "\n",
    "    Args:\n",
    "        settings: StereoTrackerSettings instance\n",
    "        iteration: Iteration of the regression cascade\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(\"figures_pytorch\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Sampling grid for landmarks\n",
    "    max_x, max_y = 240, 240\n",
    "    patch_size = 32\n",
    "    settings.patch_size = patch_size\n",
    "    settings.max_x = max_x\n",
    "    settings.max_y = max_y\n",
    "    patch_shape = (patch_size, patch_size)\n",
    "    patch_shape = np.array(patch_shape)\n",
    "    patch_half_shape = np.require(np.round(patch_shape / 2), dtype=int)\n",
    "    start = -patch_half_shape\n",
    "    end = patch_half_shape\n",
    "    sampling_grid = np.mgrid[start[0]:end[0], start[1]:end[1]]\n",
    "    sampling_grid = sampling_grid.swapaxes(0, 2).swapaxes(0, 1).astype(np.float32)\n",
    "\n",
    "    sg_size = sampling_grid.shape\n",
    "    pts_size = (21, 2)\n",
    "\n",
    "    sampling_grid = torch.FloatTensor(sampling_grid).cuda()\n",
    "    sampling_grid = sampling_grid.contiguous().view((1,) + sg_size).expand((pts_size[0],) + sg_size)\n",
    "    old_size = sampling_grid.size()\n",
    "    sampling_grid = sampling_grid.contiguous().view((1,) + old_size)\n",
    "\n",
    "    ###########################\n",
    "    # Data and normalization\n",
    "    ###########################\n",
    "\n",
    "    # Get data shape and normalization\n",
    "    tr_img0, tr_img1, tr_pts0, tr_pts1, tr_init0, tr_init1 = tu.load_data(\"data/processed/CNN_database.h5\", \"training\")\n",
    "    val_img0, val_img1, val_pts0, val_pts1, val_init0, val_init1 = tu.load_data(\n",
    "        \"data/processed/CNN_database.h5\", \"validation\")\n",
    "\n",
    "    # Random idx to plot figures.\n",
    "    idxs_train = np.random.permutation(tr_img0.shape[0])[:4]\n",
    "    idxs_val = np.random.permutation(val_img0.shape[0])[:4]\n",
    "\n",
    "    ###########################\n",
    "    # Neural Net\n",
    "    ###########################\n",
    "\n",
    "    n_filters = 32\n",
    "    hidden_dim = 512\n",
    "    input_dim = 42\n",
    "    output_dim = 84\n",
    "\n",
    "    list_models = [SubCNN(input_dim, output_dim, n_filters, hidden_dim).cuda() for i in range(settings.max_iteration)]\n",
    "\n",
    "    model_parameters = [{'params': list_models[i].parameters()} for i in range(settings.max_iteration)]\n",
    "\n",
    "    optimizer = optim.Adam(model_parameters, lr=settings.learning_rate)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss(size_average=True).cuda()\n",
    "    # loss_fn2 = torch.nn.L1Loss(size_average=True).cuda()\n",
    "\n",
    "    ###########################\n",
    "    # Monitoring\n",
    "    ###########################\n",
    "\n",
    "    # Initialize a dict to hold monitoring metrics\n",
    "    d_losses = {\"train_losses\": [],\n",
    "                \"train_mean_shape_rmse\": [],\n",
    "                \"train_std_shape_rmse\": [],\n",
    "                \"val_mean_shape_rmse\": [],\n",
    "                \"val_std_shape_rmse\": [],\n",
    "                \"val_mean_shape_rmse_closed\": [],\n",
    "                \"val_std_shape_rmse_closed\": [],\n",
    "                \"val_mean_shape_rmse_open\": [],\n",
    "                \"val_std_shape_rmse_open\": [],\n",
    "                \"best_val_mean_shape_rmse\": [],\n",
    "                \"duration\": []}\n",
    "\n",
    "    #################\n",
    "    # Training\n",
    "    ################\n",
    "    lu.print_start_training()\n",
    "\n",
    "    for e in range(settings.nb_epoch):\n",
    "\n",
    "        s = time()\n",
    "\n",
    "        d_loss = {0: [], 1:[], 2:[]}\n",
    "\n",
    "        num_elem = tr_img0.shape[0]\n",
    "        num_batches = num_elem // settings.batch_size\n",
    "        list_batches = np.array_split(np.arange(num_elem), num_batches)\n",
    "\n",
    "        # list_batches += list_batches\n",
    "\n",
    "        list_models_epoch = list_models\n",
    "        # if e < 5:\n",
    "        #     list_models_epoch = list_models[:1]\n",
    "        # elif 5 <= e < 10:\n",
    "        #     list_models_epoch = list_models[:2]\n",
    "        # else:\n",
    "        #     list_models_epoch = list_models\n",
    "\n",
    "        for batch_idxs in tqdm(list_batches):\n",
    "\n",
    "            start = batch_idxs[0]\n",
    "            end = batch_idxs[-1]\n",
    "\n",
    "            img0_batch = tr_img0[start: end + 1]\n",
    "            img1_batch = tr_img1[start: end + 1]\n",
    "\n",
    "            pts0_batch = tr_pts0[start: end + 1]\n",
    "            pts1_batch = tr_pts1[start: end + 1]\n",
    "\n",
    "            init0_batch = tr_init0[start: end + 1]\n",
    "            init1_batch = tr_init1[start: end + 1]\n",
    "\n",
    "            y_true, y_init, y_pred, list_dy_pred, list_y_pred = tu.forward_pass(settings, list_models_epoch,\n",
    "                                                                                img0_batch, img1_batch,\n",
    "                                                                                pts0_batch, pts1_batch,\n",
    "                                                                                init0_batch, init1_batch,\n",
    "                                                                                sampling_grid)\n",
    "\n",
    "            g = make_dot(y_pred)\n",
    "            g.view()\n",
    "\n",
    "            for i in range(len(list_y_pred)):\n",
    "                loss = loss_fn(240 * list_y_pred[i], 240 * y_true)\n",
    "                d_loss[i].append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "            # Compute loss\n",
    "            total_loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Compute eval metrics\n",
    "        print(\"\")\n",
    "        for stage in range(len(list_models_epoch)):\n",
    "            print(\"Stage : %s, loss: %s\" % (stage, np.mean(d_loss[stage])))\n",
    "\n",
    "        d_losses[\"train_losses\"].append(np.mean(d_loss[len(list_models_epoch) - 1]))\n",
    "        d_losses[\"duration\"].append(time() - s)\n",
    "        d_losses, ri = tu.display_metrics(settings, d_losses, list_models_epoch, sampling_grid,\n",
    "                                          tr_img0, tr_img1, tr_pts0, tr_pts1, tr_init0, tr_init1,\n",
    "                                          val_img0, val_img1, val_pts0, val_pts1, val_init0, val_init1)\n",
    "\n",
    "        # Plot some images\n",
    "        if e % 10 == 0:\n",
    "            # Training set\n",
    "            tu.plot_regression(settings, list_models, sampling_grid, e,\n",
    "                               tr_img0[idxs_train], tr_img1[idxs_train],\n",
    "                               tr_pts0[idxs_train], tr_pts1[idxs_train],\n",
    "                               tr_init0[idxs_train], tr_init1[idxs_train],\n",
    "                               \"training\")\n",
    "            tu.plot_regression(settings, list_models, sampling_grid, e,\n",
    "                               val_img0[idxs_val], val_img1[idxs_val],\n",
    "                               val_pts0[idxs_val], val_pts1[idxs_val],\n",
    "                               val_init0[idxs_val], val_init1[idxs_val],\n",
    "                               \"validation\")\n",
    "\n",
    "            # dy_true = y_true - y_init\n",
    "\n",
    "            # dy_pred = list_dy_pred[0]\n",
    "\n",
    "            # total_loss = mse_loss(240 * dy_true, 240 * dy_pred)\n",
    "            # d_loss[0].append(total_loss.cpu().data.numpy()[0])\n",
    "            # for i in range(1, len(list_dy_pred)):\n",
    "            #     dy_pred += list_dy_pred[i]\n",
    "            #     loss = mse_loss(240 * dy_true, 240 * dy_pred)\n",
    "            #     total_loss += loss\n",
    "            #     d_loss[i].append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "            # list_y_pred = [y_init + list_dy_pred[0]]\n",
    "            # for dy in list_dy_pred[1:]:\n",
    "            #     list_y_pred.append(dy + list_y_pred[-1])\n",
    "            # total_loss = 0\n",
    "            # for yp in list_y_pred:\n",
    "            #     total_loss += loss_fn(240 * yp, 240 * y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
